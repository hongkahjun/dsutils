{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from pygam import LinearGAM, GAM\n",
    "from pygam.callbacks import Deviance\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.inspection import plot_partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnGam(GAM):  \n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(SklearnGam, self).__init__(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv(file):\n",
    "    df = pd.read_csv(file)\n",
    "    print(df.head())\n",
    "    print(df.shape)\n",
    "    print(\"\")\n",
    "    print(\"Percentage of nans:\")\n",
    "    print(df.isna().mean().round(4) * 100)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_elbow_plot(x):\n",
    "    x_scaled = StandardScaler().fit_transform(x)\n",
    "    pca = PCA()\n",
    "    pca.fit(x_scaled)\n",
    "    plt.figure()\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Variance (%)')  # for each component\n",
    "    plt.title('Explained Variance')\n",
    "    plt.show()\n",
    "    return pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_biplot(score, coeff, labels=None):\n",
    "    xs = score[:, 0]\n",
    "    ys = score[:, 1]\n",
    "    n = coeff.shape[0]\n",
    "    scalex = 1.0 / (xs.max() - xs.min())\n",
    "    scaley = 1.0 / (ys.max() - ys.min())\n",
    "    plt.scatter(xs * scalex, ys * scaley)\n",
    "    for i in range(n):\n",
    "        plt.arrow(0, 0, coeff[i, 0], coeff[i, 1], color='r', alpha=0.5)\n",
    "        if labels is None:\n",
    "            plt.text(coeff[i, 0] * 1.15, coeff[i, 1] * 1.15, \"Var\" + str(i + 1), color='g', ha='center', va='center')\n",
    "        else:\n",
    "            plt.text(coeff[i, 0] * 1.15, coeff[i, 1] * 1.15, labels[i], color='g', ha='center', va='center')\n",
    "    plt.xlim(-1, 1)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.xlabel(\"PC{}\".format(1))\n",
    "    plt.ylabel(\"PC{}\".format(2))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph(formula, x_range, label=None):\n",
    "    x = x_range\n",
    "    y = formula(x)\n",
    "    plt.plot(x, y, label=label, lw=1, ls='--', color='red')\n",
    "\n",
    "\n",
    "def diagnostic_plots(x, y, model_fit=None):\n",
    "    if not model_fit:\n",
    "        model_fit = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "\n",
    "    dataframe = pd.concat([x, y], axis=1)\n",
    "    model_fitted_y = model_fit.fittedvalues\n",
    "    model_residuals = model_fit.resid\n",
    "    model_norm_residuals = model_fit.get_influence().resid_studentized_internal\n",
    "    model_norm_residuals_abs_sqrt = np.sqrt(np.abs(model_norm_residuals))\n",
    "    model_abs_resid = np.abs(model_residuals)\n",
    "    model_leverage = model_fit.get_influence().hat_matrix_diag\n",
    "    model_cooks = model_fit.get_influence().cooks_distance[0]\n",
    "\n",
    "    plot_lm_1 = plt.figure()\n",
    "    plot_lm_1.axes[0] = sns.residplot(model_fitted_y, dataframe.columns[-1], data=dataframe, lowess=True,\n",
    "                                      scatter_kws={'alpha': 0.5}, line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "\n",
    "    plot_lm_1.axes[0].set_title('Residuals vs Fitted')\n",
    "    plot_lm_1.axes[0].set_xlabel('Fitted values')\n",
    "    plot_lm_1.axes[0].set_ylabel('Residuals')\n",
    "    abs_resid = model_abs_resid.sort_values(ascending=False)\n",
    "    abs_resid_top_3 = abs_resid[:3]\n",
    "    for i in abs_resid_top_3.index:\n",
    "        plot_lm_1.axes[0].annotate(i, xy=(model_fitted_y[i], model_residuals[i]))\n",
    "\n",
    "    QQ = ProbPlot(model_norm_residuals)\n",
    "    plot_lm_2 = QQ.qqplot(line='45', alpha=0.5, color='#4C72B0', lw=1)\n",
    "    plot_lm_2.axes[0].set_title('Normal Q-Q')\n",
    "    plot_lm_2.axes[0].set_xlabel('Theoretical Quantiles')\n",
    "    plot_lm_2.axes[0].set_ylabel('Standardized Residuals')\n",
    "    abs_norm_resid = np.flip(np.argsort(np.abs(model_norm_residuals)), 0)\n",
    "    abs_norm_resid_top_3 = abs_norm_resid[:3]\n",
    "    for r, i in enumerate(abs_norm_resid_top_3):\n",
    "        plot_lm_2.axes[0].annotate(i, xy=(np.flip(QQ.theoretical_quantiles, 0)[r], model_norm_residuals[i]))\n",
    "\n",
    "    plot_lm_3 = plt.figure()\n",
    "    plt.scatter(model_fitted_y, model_norm_residuals_abs_sqrt, alpha=0.5)\n",
    "    sns.regplot(model_fitted_y, model_norm_residuals_abs_sqrt, scatter=False, ci=False, lowess=True,\n",
    "                line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "    plot_lm_3.axes[0].set_title('Scale-Location')\n",
    "    plot_lm_3.axes[0].set_xlabel('Fitted values')\n",
    "    plot_lm_3.axes[0].set_ylabel('$\\sqrt{|Standardized Residuals|}$')\n",
    "\n",
    "    for i in abs_norm_resid_top_3:\n",
    "        plot_lm_3.axes[0].annotate(i, xy=(model_fitted_y[i], model_norm_residuals_abs_sqrt[i]))\n",
    "\n",
    "    plot_lm_4 = plt.figure()\n",
    "    plt.scatter(model_leverage, model_norm_residuals, alpha=0.5)\n",
    "    sns.regplot(model_leverage, model_norm_residuals, scatter=False, ci=False, lowess=True,\n",
    "                line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8})\n",
    "    plot_lm_4.axes[0].set_xlim(0, max(model_leverage) + 0.01)\n",
    "    plot_lm_4.axes[0].set_ylim(-3, 5)\n",
    "    plot_lm_4.axes[0].set_title('Residuals vs Leverage')\n",
    "    plot_lm_4.axes[0].set_xlabel('Leverage')\n",
    "    plot_lm_4.axes[0].set_ylabel('Standardized Residuals')\n",
    "\n",
    "    leverage_top_3 = np.flip(np.argsort(model_cooks), 0)[:3]\n",
    "    for i in leverage_top_3:\n",
    "        plot_lm_4.axes[0].annotate(i, xy=(model_leverage[i], model_norm_residuals[i]))\n",
    "\n",
    "    p = len(model_fit.params)  # number of model parameters\n",
    "    graph(lambda a: np.sqrt((0.5 * p * (1 - a)) / a), np.linspace(0.001, max(model_leverage), 50), 'Cook\\'s distance')\n",
    "    graph(lambda a: np.sqrt((1 * p * (1 - a)) / a), np.linspace(0.001, max(model_leverage), 50))\n",
    "    plot_lm_4.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feature_ranking(x, y, labels=None):\n",
    "    parameters = {\n",
    "        'n_estimators': [10],\n",
    "        'max_depth': [1, 7],\n",
    "        'max_features': (1, 0.2)\n",
    "    }\n",
    "    rf = RandomForestRegressor(criterion='mse')\n",
    "    rf_cv = GridSearchCV(rf, parameters, cv=5, iid=False, return_train_score=True, refit=True, scoring='neg_mean_squared_error')\n",
    "    rf_cv.fit(x, y)\n",
    "    best_rf = rf_cv.best_estimator_\n",
    "    if labels is None:\n",
    "        labels = np.arange(x.shape[0])\n",
    "    order = np.arange(x.shape[0])\n",
    "    ranked_features = [n for _, n, _ in sorted(zip(best_rf.feature_importances_, labels, order), reverse=True)]\n",
    "    ordered_indices = [n for _, _, n in sorted(zip(best_rf.feature_importances_, labels, order), reverse=True)]\n",
    "    return ranked_features, ordered_indices, best_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GamCV(x, y):\n",
    "    lams = np.random.rand(10, x.shape[1])\n",
    "    lams = np.exp(lams)\n",
    "    linear_gam = GAM(n_splines=10, max_iter=100)\n",
    "    parameters = {\n",
    "        'lam': [x for x in lams]\n",
    "    }\n",
    "    gam_cv = GridSearchCV(linear_gam, parameters, cv=5, iid=True, return_train_score=True, refit=True, scoring='neg_mean_squared_error')\n",
    "    gam_cv.fit(x, y)\n",
    "    cv_results_df = pd.DataFrame(gam_cv.cv_results_).sort_values(by='mean_test_score', ascending=False)\n",
    "    return gam_cv, cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gam(x, y):\n",
    "    lams = np.random.rand(100, x.shape[1])\n",
    "    lams = np.exp(lams)\n",
    "    linear_gam = GAM(n_splines=10, max_iter=1000)\n",
    "    x = StandardScaler().fit_transform(x)\n",
    "    cv_results = linear_gam.gridsearch(x, y, return_scores=True, lam=lams, progress=False)\n",
    "    cv_results_df = pd.DataFrame(cv_results, index=['score']).T.sort_values(by='score', ascending=False)\n",
    "    return linear_gam, cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def en(x, y):\n",
    "    parameters = {\n",
    "        'en__alpha': [2 ** -7, 2 ** 7],\n",
    "        'en__l1_ratio': [0, 0.1]\n",
    "    }\n",
    "    en_pipeline = Pipeline([('scale', StandardScaler()), ('en', ElasticNet(max_iter=10000))])\n",
    "    en_cv = GridSearchCV(en_pipeline, parameters, cv=5, iid=False, return_train_score=True, refit=True, scoring='neg_mean_squared_error')\n",
    "    en_cv.fit(x, y)\n",
    "    cv_results_df = pd.DataFrame(en_cv.cv_results_).sort_values(by='mean_test_score', ascending=False)\n",
    "    return en_cv, cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(x, y):\n",
    "    parameters = {\n",
    "        'n_estimators': [100],\n",
    "        'max_depth': [1, 5],\n",
    "        'max_features': (1, 0.2)\n",
    "    }\n",
    "    _rf = RandomForestRegressor(criterion='mse', oob_score=True)\n",
    "    rf_cv = GridSearchCV(_rf, parameters, cv=5, iid=False, return_train_score=True, refit=True,\n",
    "                         scoring='neg_mean_squared_error')\n",
    "    rf_cv.fit(x, y)\n",
    "    cv_results_df = pd.DataFrame(rf_cv.cv_results_).sort_values(by='mean_test_score', ascending=False)\n",
    "    return rf_cv, cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdp(est, x, feature, feature_names, no):\n",
    "    fig = plt.figure(figsize=(24, 18))\n",
    "    if no == -1:\n",
    "        plot_partial_dependence(est, x, feature, feature_names, fig=fig)\n",
    "    else:\n",
    "        plot_partial_dependence(est, x, feature[:no], feature_names, fig=fig)\n",
    "    fig = plt.gcf()\n",
    "    fig.suptitle('Partial dependence', fontsize=30)\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gam_pdp(est, feature, feature_names, no):\n",
    "    if no == -1:\n",
    "        plt.figure();\n",
    "        fig, axs = plt.subplots(1, len(feature_names), figsize=(40, 8))\n",
    "        for i, ax in enumerate(axs):\n",
    "            XX = est.generate_X_grid(term=i)\n",
    "            ax.plot(XX[:, i], est.partial_dependence(term=i, X=XX))\n",
    "            ax.plot(XX[:, i], est.partial_dependence(term=i, X=XX, width=.95)[1], c='r', ls='--')\n",
    "            if i == 0:\n",
    "                ax.set_ylim(-30, 30)\n",
    "            ax.set_title(feature_names[feature.index(i)])\n",
    "    else:\n",
    "        plt.figure();\n",
    "        fig, axs = plt.subplots(1, no, figsize=(40, 8))\n",
    "        for i, ax in enumerate(axs):\n",
    "            f_no = int(feature[i])\n",
    "            XX = est.generate_X_grid(term=f_no)\n",
    "            ax.plot(XX[:, f_no], est.partial_dependence(term=f_no, X=XX))\n",
    "            ax.plot(XX[:, f_no], est.partial_dependence(term=f_no, X=XX, width=.95)[1], c='r', ls='--')\n",
    "            if f_no == 0:\n",
    "                ax.set_ylim(-30, 30)\n",
    "            ax.set_title(feature_names[i])\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_test_results(_x_train, _x_test, _y_train, _y_test):\n",
    "    gam_cv, gam_results_df = gam(_x_train, _y_train)\n",
    "    en_cv, en_results_df = en(_x_train, _y_train)\n",
    "    rf_cv, rf_results_df = rf(_x_train, _y_train)\n",
    "    result_index = ['GAM', 'EN', 'RF']\n",
    "    result_column = ['MSE', 'R2']\n",
    "    test_results = np.zeros((3, 2))\n",
    "    test_results[0, 0] = mean_squared_error(_y_test, gam_cv.predict(_x_test))\n",
    "    test_results[0, 1] = r2_score(_y_test, gam_cv.predict(_x_test))\n",
    "    test_results[1, 0] = mean_squared_error(_y_test, en_cv.predict(_x_test))\n",
    "    test_results[1, 1] = r2_score(_y_test, en_cv.predict(_x_test))\n",
    "    test_results[2, 0] = mean_squared_error(_y_test, rf_cv.predict(_x_test))\n",
    "    test_results[2, 1] = r2_score(_y_test, rf_cv.predict(_x_test))\n",
    "    results_df = pd.DataFrame(test_results, result_index, result_column)\n",
    "    return [gam_cv, en_cv, rf_cv], [gam_results_df, en_results_df, rf_results_df], results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "csv_file = 'winequality-red.csv'\n",
    "dataset = import_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_values = dataset.values\n",
    "x_all = dataset_values[:, :-1]\n",
    "y_all = dataset_values[:, -1]\n",
    "features = list(dataset)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = pca_elbow_plot(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaled = StandardScaler().fit_transform(x_all)\n",
    "x_all_pca = pca_model.transform(x_scaled)\n",
    "pca_biplot(x_all_pca[:, 0:2], np.transpose(pca_model.components_[0:2, :]), labels=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic_plots(dataset.iloc[:, :-1], dataset.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranked, indices_ranked, ranked_model = rf_feature_ranking(x_all, y_all, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gam_rank, gam_results = gam(x_all, y_all)\n",
    "# gam_pdp(gam_rank, indices_ranked, feature_ranked, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdp(ranked_model, x_all, indices_ranked, feature_ranked, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.2)\n",
    "models, cv_result_list, test_results_df = cal_test_results(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
